{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Modulo5Capsula1_abiertaUGR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vD-6nUjHFjP"
      },
      "source": [
        "![cabecera_slide_abiertaugr_bigdata.jpg](https://i.imgur.com/HXn24wC.jpg)\n",
        "## Módulo 5.1 Clasificación ¿Qué, para qué y cómo?\n",
        "\n",
        "**Autor**: \n",
        "\n",
        "*Por* Prof. Alberto Fernández Hilario\n",
        "\n",
        "Profesor Titular de Universidad de Granada. Instituto Andaluz Interuniversitario en Data Science and Computational Intelligence (DasCI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8Y_zJaSHFjR"
      },
      "source": [
        "## Breves Instrucciones\n",
        "\n",
        "### Recordatorio: Introducción a NoteBook\n",
        "\n",
        "El cuaderno de *Jupyter* (Python) es un enfoque que combina bloques de texto (como éste) junto con bloques o celdas de código. La gran ventaja de este tipo de celdas, es su interactividad, ya que pueden ser ejecutadas para comprobar los resultados directamente sobre las mismas. \n",
        "\n",
        "**Muy importante**: el orden de las instrucciones (bloques de código) es fundamental, por lo que cada celda de este cuaderno debe ser ejecutada secuencialmente. En caso de omitir alguna, puede que el programa lance un error (se mostrará un bloque salida con un mensaje en inglés de color rojo), así que se deberá comenzar desde el principio en caso de duda. Para hacer este paso más sencillo, se puede acceder al menú “Entorno de Ejecución” y pulsar sobre “Ejecutar anteriores”. \n",
        "\n",
        "¡Ánimo!\n",
        "\n",
        "Haga clic en el botón \"play\" en la parte izquierda de cada celda de código. Las líneas que comienzan con un hashtag (#) son comentarios y no afectan a la ejecución del programa.\n",
        "\n",
        "También puede pinchar sobre cada celda y hacer \"*ctrl+enter*\" (*cmd+enter* en Mac).\n",
        "\n",
        "Cuando se ejecute el primero de los bloques, aparecerá el siguiente mensaje: \n",
        "\n",
        "\"*Advertencia: Este cuaderno no lo ha creado Google.*\n",
        "\n",
        "*El creador de este cuaderno es \\<autor\\>@go.ugr.es. Puede que solicite acceso a tus datos almacenados en Google o que lea datos y credenciales de otras sesiones. Revisa el código fuente antes de ejecutar este cuaderno. Si tienes alguna pregunta, ponte en contacto con el creador de este cuaderno enviando un correo electrónico a \\<autor\\>@go.ugr.es.”*\n",
        "\n",
        "No se preocupe, deberá confiar en el contenido del cuaderno (Notebook) y pulsar en \"*Ejecutar de todos modos*\". Todo el código se ejecuta en un servidor de cálculo externo y no afectará en absoluto a su equipo informático. No se pedirá ningún tipo de información o credencial, y por tanto podrá seguir con el curso de forma segura. \n",
        "\n",
        "Cada vez que ejecute un bloque, verá la salida justo debajo del mismo. La información suele ser siempre la relativa a la última instrucción, junto con todos los `print()` (orden para imprimir) que haya en el código."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbfhwW3gYubW"
      },
      "source": [
        "##**ÍNDICE** \n",
        "\n",
        "En este *notebook*: \n",
        "1. Se presentará la tarea de Clasificación en Machine Learning.\n",
        "2. Se describirá cómo medir la calidad de los modelos de clasificación, y cuáles son las métricas más importantes.\n",
        "3. Se mostrará un ejemplo sobre cómo aplicar el proceso de aprendizaje y validación sobre un conjunto de datos.\n",
        "    \n",
        "Contenidos:\n",
        "1. [Introducción a clasificación](#sec:clasificacion)  \n",
        "2. [Midiendo la calidad de los modelos de clasificación en Machine Learning](#sec:eval)   \n",
        "3. [Ejemplo completo sobre un caso de estudio](#sec:dataset)  \n",
        "4. [Referencias bibliográficas](#sec:biblio) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN3JS6iYMcnU"
      },
      "source": [
        "## **1. INTRODUCCIÓN A CLASIFICACIÓN**\n",
        "\n",
        "La tarea de aprendizaje en clasificación se centra en crear lo que se conoce como \"*discriminante*\". Este término se refiere a una función que sea capaz de distinguir entre las  clases o etiquetas de salida representadas en el problema. Esta función discriminante utilizará los valores de las variables de entrada que definen el caso de estudio o problema con el que se está trabajando. De este modo se genera una división (por ejemplo una simple línea recta) que parte el conjunto de datos en dos o más secciones, creando zonas que identifican a cada una de las clases.\n",
        "\n",
        "En la siguiente figura, se observan dos tipos de funciones discriminantes en clasificación, una sencilla de tipo lineal (una recta), y otra más compleja (un función polinómica). Ambas son utilizadas para determinar las zonas del espacio que pertenecen a cada una de las clases de un mismo problema de dos variables.\n",
        "\n",
        "![Frontera de decisión de una función discriminante lineal en clasificación](https://i.imgur.com/f6dqpWP.png)\n",
        "\n",
        "![Frontera de decisión de una función discriminante polinomial en clasificación](https://i.imgur.com/zT0mh0b.png)\n",
        "\n",
        "Es importante destacar que las funciones discriminantes que componen el modelo de clasificación tienen una doble misión. Como tarea principal, se utilizan como herramientas predictivas frente a nuevos ejemplos. Adicionalmente, una ventaja añadida es permitir la extracción de conocimiento subyacente en los datos mediante la propia representación del modelo. \n",
        "\n",
        "Esto dependerá de la denominada *interpretabilidad* del modelo, es decir, si su representación es simple o cercana a la cognición y semántica humana, y por tanto explica los datos de una manera parecida a como lo haría una persona. Por ejemplo, si se aprende un modelo para distinguir pacientes con o sin una patología concreta a través de un panel genético reducido, tenemos el conocimiento de los principales genes a estudiar para pacientes de riesgo. Esta información permitiría trabajar en inhibidores de dichos genes para buscar un tratamiento útil y efectivo.\n",
        "\n",
        "![Modelos interpretables que explican su funcionamiento](https://i.imgur.com/FSERM3z.png)\n",
        "\n",
        "Existen diferentes tipos de *funciones discriminantes*, lo que identificará distintos paradigmas o modelos de clasificación. Podemos usar discriminantes lineales como en la figura anterior (una simple función lineal entre las variables de entrada), un conjunto de reglas (un listado de conjunciones atributo-valor), o un entorno o vecindario sobre el conjunto de datos de entrenamiento (similitud entre muestras). También existen sistemas más complejos como las llamadas redes neuronales, o las máquinas de vectores soporte. \n",
        "\n",
        "Al primer grupo de modelos presentado (lineales y reglas) se los denomina \"modelos de caja blanca\" o \"sistemas transparentes\" porque permiten una interpretación directa por parte del usuario, y por tanto suelen preferirse cuando se precisa un alto nivel de confianza en el modelo. El segundo tipo de modelos (redes neuronales) son los conocidos como de \"caja negra\" y, aunque suelen alcanzar un mayor ratio de acierto, no es trivial explicar el porqué producen una salida concreta. \n",
        "\n",
        "A lo largo del presente módulo se analizarán algunos de los paradigmas de clasificación más conocidos y representativos de ambos paradigmas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPZaTghu57-1"
      },
      "source": [
        "## **2. MIDIENDO LA CALIDAD DE LOS MODELOS DE CLASIFICACIÓN EN MACHINE LEARNING**\n",
        "\n",
        "Todas las metodologías o técnicas de Machine Learning necesitan una función de evaluación o métrica para estimar cuantitativamente la capacidad de generalización del modelo, es decir, cómo de bien realizará predicciones sobre nuevos datos.\n",
        "\n",
        "En el contexto de clasificación, la más común de todas estas medidas es conocida como la tasa de aciertos en la predicción (en inglés *accuracy*). Sin embargo, se debe tener en cuenta que hay muchas otras, y que no necesariamente tiene que estar identificado por un simple valor numérico. \n",
        "\n",
        "Lo fundamental en este caso es que la elección de una medida concreta debe estar guiada por el objetivo final. Este objetivo puede ser simplemente acertar en el máximo número de instancias, o puede que haya alguna clase en particular que sea más interesante de cara al estudio. Por ejemplo, en un sistema automático de diagnóstico, existe más riesgo en dar una falsa predicción negativa (dar el alta a un paciente enfermo), que la contraria (identificar un paciente sano como enfermo)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSsWDngs54uO"
      },
      "source": [
        "### **2.1 Matriz de confusión**\n",
        "\n",
        "Para la definición de cualquiera de las métricas de evaluación en clasificación, se parte de la llamada “*matriz de confusión*”. Ésta no es más que una tabla que cruza las predicciones con la clasificación real (en inglés *ground truth*). Así, permite separar los aciertos y fallos por parejas de clases, lo que proporciona un mayor conocimiento sobre qué clases son más difíciles de clasificar, o cuáles son aquéllas que tienden a \"mezclarse\".\n",
        "\n",
        "Considerese un problema de clasificación binaria, con una clase positiva (`pos`) y otra negativa (`neg`), así como un clasificador aprendido que se quiere evaluar. Según la siguiente figura, los tipos de predicciones serían:\n",
        "\n",
        "<img src=\"https://i.imgur.com/jqbfLUY.png\" width=\"400\" alt=\"Matriz de confusión para dos clases\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPzOnfS46FS9"
      },
      "source": [
        "Es momento de plantear un ejemplo muy sencillo de matriz de confusión. Para ello, se utilizarán dos listas de valores que corresponderán a la salida real, y la predicción del modelo. Ambas se notarán como ```y_real``` e ```y_pred``` respectivamente. Al ejectuar el siguiente trozo de código se mostrará la matriz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqFv-7EQ6Hos"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_real = [\"pos\", \"neg\", \"pos\", \"neg\", \"neg\", \"pos\"] #etiquetas reales\n",
        "y_pred = [\"pos\", \"pos\", \"pos\", \"neg\", \"neg\", \"pos\"] #predicciones de ML\n",
        "\n",
        "\n",
        "confusion_matrix(y_real, y_pred, labels=[\"pos\", \"neg\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0N8UVnYxyV1W"
      },
      "source": [
        "Obsérvese que se ha cometido un único \"fallo\", en este caso asociado a la segunda clase \"*neg*\" (negativo). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2iLT-G56KJ4"
      },
      "source": [
        "### **2.2 Porcentaje de acierto (accuracy)**\n",
        "\n",
        "Si se identifica cada casilla en la matriz anterior como: \n",
        "\n",
        "-\tVerdadero Positivo (TP): instancia positiva, predicha positiva.\n",
        "-\tFalso Positivo (FP): instancia negativa, predicha positiva.\n",
        "-\tVerdadero Negativo (TN): instancia negativa, predicha negativa.\n",
        "- Falso Negativo (FN): instancia positiva, predicha negativa.\n",
        "\n",
        "La primera de las métricas mencionadas, la tasa de acierto o *accuracy* se obtiene mediante la siguiente fórmula:\n",
        "\n",
        "$\n",
        "accuracy = \\frac{TP+TN}{(TP+FP+TN+FN)}\n",
        "$\n",
        "\n",
        "\n",
        "que, como se puede observar, indica la proporción de instancias correctamente clasificadas con respecto al total. \n",
        "\n",
        "A continuación, se chequea qué tal se comporta el modelo obtenido de acuerdo al ejemplo anterior que distingue entre `neg` y `pos`. Para ello, se usa la función ```accuracy_score``` que toma como parámetros las listas o arrays de valores reales de salida y predichos, respectivamente. El valor que se obtiene está indicado en forma de \"ratio\" (tanto por uno), si bien es común expresar el *accuracy* en formato porcentual. Para ello, bastará con multiplicar el valor obtenido por 100.0. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2xD_s6r6NmK"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_score(y_real, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrcznTvD6QyR"
      },
      "source": [
        "Se ha obtenido un valor bastante alto, casi un 85% de acierto. Esto es debido a únicamente se falló en una de 6 instancias, como se indicó previamente. Para observar el comportamiento de esta métrica, se procede a comprobar las diferencias con otra predicción no tan acertada (```y_pred2```):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkyGnD726TR2"
      },
      "source": [
        "#Se falla en la mitad de las ocasiones...\n",
        "y_pred2 = [\"neg\", \"pos\", \"pos\", \"neg\", \"neg\", \"neg\"] \n",
        "#Por comodidad, se recuerda la lista de valores inicial:\n",
        "y_real  = [\"pos\", \"neg\", \"pos\", \"neg\", \"neg\", \"pos\"] #etiquetas reales\n",
        "\n",
        "accuracy_score(y_real, y_pred2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O28Y2K90zzp_"
      },
      "source": [
        "En este caso, la calidad del modelo ha bajado hasta el 50% de acierto. Como se ha podido determinar, la métrica *accuracy* cuantifica el ratio de instancias bien clasificadas con respecto al total, independientemente de la clase a la que pertenecen. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahxJdZ-L6Sk2"
      },
      "source": [
        "### **2.3 Métricas individuales por clase**\n",
        "\n",
        "En ocasiones, es mucho más interesante evaluar el acierto de manera independiente para cada una de las clases. Esto es necesario cuando una de dichas clases tiene mayor relevancia, lo que sucede en muchos casos de estudio dentro de la biomedicina, como en la detección de enfermedades neurológicas donde interesa poner el foco en aquéllas que necesiten una atención temprana.  \n",
        "\n",
        "Por ese motivo, existen métricas individuales como las siguientes:\n",
        "\n",
        "- Sensibilidad (*Sensitivity*) o ratio de aciertos positivos ($TP_{rate}$). Se obtiene como $sensitivity = \\frac{TP}{TP+FN}$\n",
        "- Especificidad (*Specificity*, *recall*) o ratio de aciertos negativos ($TN_{rate}$). Se obtiene como $specificity = \\frac{TN}{TN+FP}$\n",
        "- Precisión. Se refiere al ratio de ejemplos positivos correctamente identificados con respecto al total, buscando reducir el número de \"falsas alarmas\". Se obtienen como $precision = \\frac{TP}{TP+FP}$\n",
        "\n",
        "Puesto que el uso de valores individuales no permite una visión global de la calidad del modelo, resulta muy común resumir o agregar estas medidas, utilizando por ejemplo la métrica conocida como *F-measure*, que agrega *precision* y *recall*:\n",
        "\n",
        "\\begin{equation}\n",
        "F1 = 2*\\frac{precision*recall}{precision+recall}\n",
        "\\end{equation}\n",
        "\n",
        "De acuerdo a lo anterior, el siguiente paso será analizar qué tal rendimiento se alcanza para los dos ejemplos anteriores de predicción de \"neg\" versus \"pos\" de acuerdo a las medidas individuales. Para ello, es importante indicar cuál es la clase que se considera como \"positiva\", que en este caso particular se decide sea \"pos\"; para lo cual se usa el parámetro ```pos_label```. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKWsor-Q6X7l"
      },
      "source": [
        "from sklearn.metrics import recall_score, precision_score, f1_score\n",
        "\n",
        "# Primera predicción\n",
        "recall = recall_score(y_real, y_pred, pos_label=\"pos\")\n",
        "precision = precision_score(y_real, y_pred,pos_label=\"pos\")\n",
        "f1 = f1_score(y_real, y_pred,pos_label=\"pos\")\n",
        "\n",
        "print(\"Recall {} | Precision {} | F1 {}\".format(recall,precision,f1))\n",
        "\n",
        "# Segunda predicción\n",
        "recall = recall_score(y_real, y_pred2,pos_label=\"pos\")\n",
        "precision = precision_score(y_real, y_pred2,pos_label=\"pos\")\n",
        "f1 = f1_score(y_real, y_pred2,pos_label=\"pos\")\n",
        "\n",
        "print(\"Recall {} | Precision {} | F1 {}\".format(recall,precision,f1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LkICN_X6cEL"
      },
      "source": [
        "Resulta un poco tedioso tener que preguntar por todas y cada una de las medidas de manera individual. ¿No existe una función para realizar un resumen de las principales de ellas?\n",
        "\n",
        "La respuesta es por supuesto que sí, y se denomina ```classification_report```. En el siguiente bloque se enseña la sintaxis de su uso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA4PTwep6eFX"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "etiquetas = ['pos', 'neg']\n",
        "\n",
        "print(\"Analizando modelo #1 (mejor comportamiento)\")\n",
        "print(classification_report(y_real, y_pred, target_names=etiquetas))\n",
        "\n",
        "print(\"Analizando modelo #2 (peor comportamiento)\")\n",
        "print(classification_report(y_real, y_pred2, target_names=etiquetas))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIqiPSWU6gEd"
      },
      "source": [
        "Para cada una de los dos resúmenes que han sido generados arriba, la información que se observa es la siguiente:\n",
        "\n",
        "- En primer lugar (filas 1 y 2), para cada una de las clases que contiene el problema (\"pos\" y \"neg\" en nuestro caso) se muestra la *precisión, recall, f1* y número de muestras (```support```). \n",
        "- En segundo lugar, tras un espacio en blanco, se indican las métricas de accuracy:\n",
        "  - Accuracy global (bajo la columna f1).\n",
        "  - Accuracy \"macro promedio\", promediando la media no ponderada por etiqueta de clase.  \n",
        "  - Accuracy \"promedio ponderado\", promediando la media ponderada de soporte por etiqueta.\n",
        "\n",
        "Obsérvese que, en la clasificación binaria, el \"recall\" de la clase positiva se conoce también como \"sensibilidad\"; mientras que el \"recall\" de la clase negativa es \"especificidad\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TFVKM5h6ifq"
      },
      "source": [
        "### **2.4 Métricas gráficas: Área bajo la Curva ROC**\n",
        "\n",
        "Por último, una métrica que resume numérica y visualmente la calidad de los modelos es la denominada como Área bajo la Curva ROC (en inglés *Area Under the ROC Curve – AUC*). \n",
        "\n",
        "Para ello, en lugar de la matriz de confusión, se utiliza el grado de confianza de salida de cada predicción, es decir, cómo de \"seguro\" está el clasificador de la decisión que ha tomado. Este valor se puede utilizar como \"umbral\" para forzar al clasificador a realizar la predicción como \"clase positiva\" siempre que su confianza sea mayor a dicho valor. Por defecto el valor de este  umbral se establece como 0.5, es decir, que el clasificador esté al menos un 50% seguro que la clase real sea positiva. Este valor base de 0.5 se puede disminuir, con lo que habría más instancias predichas como positivas (y posiblemente más falsos positivos) o aumentar (el caso totalmente contrario). \n",
        "\n",
        "La curva ROC representa cómo varían los valores de sensibilidad $TP_{rate}$ y ratio de falsos positivos ($FP_{rate}$ = $1-TN_{rate}$) si se modificase el anterior umbral. Lógicamente, si el umbral se fija a 0.0, entonces todas las instancias se clasificarán directamente como positivas (esquina superior derecha de la gráfica). Si fuese 1.0, entonces solamente cuando haya una certeza absoluta (100% de confianza) las instancias se clasificarían como positivas (corte con el eje de abscisas). Cada posible valor intermedio representa un valor en la curva, e implica un equilibrio diferente entre $TP_{rate}$ y $FP_{rate}$. \n",
        "\n",
        "Debido al uso de la probabilidad de la clase positiva, esta aproximación gráfica funciona únicamente para clasificación de tipo binaria (dos clases máximo).\n",
        "\n",
        "En el siguiente ejemplo se ha utilizado un código relativamente complicado para representar esta gráfica o curva ROC. Por el momento, se deben ignorar los detalles técnicos de programación, puesto que más adelante se obtendrá el mismo resultado mediante una única línea de código."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw7WaJc56j6u"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "\n",
        "#Salidas\n",
        "y_real = np.array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n",
        "y_probs = np.array([0.1, 0.2, 0.5, 0.4, 0.7, 0.35, 0.8, 0.65, 1.0, 0.4, 0.75, 0.1]) \n",
        "#para \"y_pred\" (ahora llamado y_probs) en lugar de etiquetas, utilizamos probabilidades\n",
        "\n",
        "#Cómputo de las métricas de calidad\n",
        "roc_auc = roc_auc_score(y_real, y_probs)\n",
        "fpr, tpr, _ = roc_curve(y_real, y_probs)\n",
        "\n",
        "#Pintamos la figura\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='darkorange',\n",
        "         lw=lw, label='Curva ROC (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('Ratio de Falsos Positivos (FP_rate)')\n",
        "plt.ylabel('Ratio de Verdaderos Positivos (TP_rate)')\n",
        "plt.title('Ejemplo de Curva ROC')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtMc4uNa6l-Z"
      },
      "source": [
        "En toda curva ROC, lo ideal es que la curva esté cercana a la esquina superior izquierda (alta sensibilidad (```TP_rate```), baja tasa de falsos positivos). Estar sobre la línea diagonal implica que las predicciones son cercanas a la aleatoriedad."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfDD17nS6neX"
      },
      "source": [
        "Además de la propia gráfica, se calcula un valor numérico asociado a la integral (área) de la curva mostrada. Como se puede deducir fácilmente, este cálculo de la métrica AUC no es trivial, pero afortunadamente la mayoría de los Software de Machine Learning lo incorpora. En cualquier caso, si se ignoran los valores de “predicciones de probabilidad” y por tanto se contase con un único punto en la curva ROC (el asociado al umbral por defectdo de 0.5), la fórmula que calcula AUC sería la siguiente:\n",
        "\n",
        "\\begin{equation}\n",
        "AUC = \\frac{1 + TP_{rate} - FP_{rate}}{2}\n",
        "\\end{equation}\n",
        "\n",
        "Como curiosidad, es necesario comentar que el AUC en un único punto y la medida accuracy son exactamente iguales cuando se dispone del mismo número de instancias de las clases positiva y negativa. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo3h6f7lH_Am"
      },
      "source": [
        "## **3. EJEMPLO COMPLETO SOBRE EL CASO DE ESTUDIO DE DETECCIÓN DE MELANOMA MEDIANTE DATOS ÓMICOS.**\n",
        "\n",
        "En esta sección, se presenta una visión general del proceso de creación de modelos para clasificación con algoritmos de Machine Learning. \n",
        "\n",
        "Para ello, se comienza recuperando el conjunto de datos con información ómica para el caso de estudio sobre melanoma. El resto de secciones están dedicadas al proceso general de extracción de conocimiento en Ciencia de Datos, a saber, carga del conjunto de datos, particionamiento en entrenamiento y test, aprendizaje de modelos, y validación de la calidad de los mismos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VSYt7b2BECj"
      },
      "source": [
        "### **3.1 Recuperando los datos de la matriz de expresión genética**\n",
        "\n",
        "\n",
        "Como ya se indicó al comienzo de este curso, las alteraciones genómicas resultan de vital importancia en muchos campos de la Bioinformática. De este modo, el procedimiento suele partir de la toma de diferentes muestras de tejido o sangre para obtener información celular. A partir de un procedimiento de secuenciación (técnicas de *Next Generation Sequencing* o NGS), se extraen los valores de la expresión de los diferentes genes que componen el ADN de las muestras. \n",
        "\n",
        "De esta manera, se suele obtener un conjunto de datos un número de filas equivalentes al número de genes que se haya conseguido secuenciar (variables de entrada), y un número de columnas igual a las muestras que se hayan recogido (instancias). Por último, en estudios clínicos se realizan anotaciones externas sobre cada muestra. Esta serie de variables adicionales resultan útiles y relevantes tanto a nivel predictivo (como variables de salida) como descriptivo (variables de entrada), o incluso permiten una interpretación más sencilla de los resultados obtenidos. \n",
        "\n",
        "En este apartado del curso, el caso de estudio seleccionado versa sobre predicción de **melanoma cutáneo**. En concreto, se tendrán en cuenta dos clases relevantes a nivel biológico. Por un lado, muestras cuyos genes más expresados pueden considerarse asociados a células, moléculas o proteínas aparentemente 'inhibidoras' del melanoma; se denominarán de manera genérica '*immune*'. Por otro lado, muestras cuyos genes más expresados se pueden asociar con factores de transcripción asociados a microftalmia (*microphthalmia-associated transcription factor*) o simplemente '*MITF*'.\n",
        "\n",
        "Durante todo el **Módulo de Clasificación** se va a utilizar una modificación del conjunto de datos original. En concreto, se ha realizado un preprocesamiento para simplificar el problema con respecto tanto al número de variables de entrada, como a la información contenida en las instancias. También se debe hacer hincapié en que la estructura del fichero de entrada de datos (donde se almacena la matriz de expresión genética) se ha traspuesto, para seguir la notación estándar de Machine Learning en el que cada fila es una instancia, y cada columna una variable. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GDXE_2kHFjS"
      },
      "source": [
        "### **3.2 Cargar los datos y análisis exploratorio**\n",
        "\n",
        "Este procedimiento inicial se ha utilizado anteriormente, por lo que solo es necesario repetir lo que ya es conocido (ver Módulos 2 y 4). Al final del trozo de código se imprimen las 5 primeras muestras para confirmar que se ha cargado correctamente. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FFxCHjDHFjT"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Cargamos los datos ómicos de la matriz de expresión desde un fichero compartido en Google Drive\n",
        "gene_exp_inmune = pd.read_csv('https://drive.google.com/uc?id=1PYzEIdmnfjOnBpPDIFBE9hL1Lkj_OBCk',index_col=0)\n",
        "#Cargamos la variable clínica correspondiente a las etiquetas \"inmune\" vs. \"MITF-low\"\n",
        "clinical_info_inmune = pd.read_csv('https://drive.google.com/uc?id=1hHQfcvrFa5Jds-9tW_X4sHjKpYKdii9s',index_col=0)\n",
        "\n",
        "X, y = gene_exp_inmune, clinical_info_inmune\n",
        "\n",
        "#Imprimimos las 5 primeras muestras del conjunto de datos\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFZJuhpQCm9N"
      },
      "source": [
        "Siempre que se comienza a trabajar con un nuevo conjunto de datos, conviene comprender la estructura del mismo, es decir, número de instancias, número de variables de entrada, estadísticos descriptivos, distribución de las clases, entre otros. Esta es la etapa de exploración y análisis de datos. \n",
        "\n",
        "En primer lugar, se observa tanto la estructura del conjunto de datos, como las clases (variable de salida) y su distribución."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XZ6lHoWDkLN"
      },
      "source": [
        "print(\"Número de instancias y número de variables:\",X.shape)\n",
        "print(\"Valores de clase:\",pd.unique(y['RNASEQ-CLUSTER_CONSENHIER']))\n",
        "print(\"Número de instancias para cada clase:\\n\",y[y=='immune'].count(),y[y=='MITF-low'].count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzX4eZDlDjs_"
      },
      "source": [
        "Se ha comprobado que se está trabajando con un conjunto de datos reducido con respecto al original, en concreto con un número de genes o variables de entrada igual a 50. Asímismo, la proporción de instancias por clase se ha forzado para que se mantenga en el ratio 1:1.\n",
        "\n",
        "Por último, se pueden observar algunos de los principales estadísticos descriptivos, por ejemplo sobre los 10 primeros genes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHYrSsMWC4GF"
      },
      "source": [
        "#La orden \"describe\" muestra los principales estadísticos (solo 10 primeras variables). \n",
        "X[X.columns[0:10]].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V8W9BJoHFjq"
      },
      "source": [
        "### **3.3 Crear la partición de los datos en los conjuntos de entrenamiento y test**\n",
        "\n",
        "Por simplicidad, se utilizará una validación tipo \"*hold-out*\" por defecto. Para más detalles consúltese el **Módulo 3** sobre Aprendizaje Supervisado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n4Dug_UHFjr"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "print(\"Numero de instancias en entrenamiento: {}; y test: {}\".format(len(X_train),len(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHaLUOU6HFju"
      },
      "source": [
        "### **3.4 Entrenamiento y predicciones de un modelo de Machine Learning**\n",
        "\n",
        "Entre las diferentes técnicas disponibles, un clasificador popular y fácil de entender es el conocido como de los \"*k vecinos más cercanos*\" (en inglés *k-nearest neighbors* o *kNN*). \n",
        "\n",
        "Esta técnica es una de las estrategias más simples de aprendizaje (de hecho, en realidad no aprende): dada una nueva instancia desconocida, buscar en el conjunto de datos de entrenamiento aquellas instancias cuyas variables sean más parecidas, y asignarle la clase más frecuente entre todos estos \"vecinos\". \n",
        "\n",
        "En los próximos apartados del presente módulo, se describirán más detalles sobre el funcionamiento específico de este algoritmo. Por ahora, basta con tener una noción básica y conocer su interfaz (cómo interactuar con él), ya que es común a todos los algoritmos de aprendizaje supervisado implementados en *Scikit-Learn*. \n",
        "\n",
        "Para generar y aprender nuestro modelo se debe instanciar (crear un objeto de tipo `estimator`) y posteriormente entrenar (llamar al método `fit()`). Se recuerda la necesidad de incluir tanto las instancias de entrada `X` como sus valores de salida `y` para construir el modelo. \n",
        "\n",
        "Los pasos indicados se muestran en el siguiente trozo de código:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYywbvpNHFjv"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier # cargamos la función desde la biblioteca\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\") #ignorar esta linea \n",
        "\n",
        "knn = KNeighborsClassifier() # instanciamos el modelo (parámetros por defecto)\n",
        "knn.fit(X_train, y_train) # lo más importante: entrenamos el modelo \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jO0CFm0yY3Rs"
      },
      "source": [
        "La salida mostrada en el bloque anterior es la configuración del clasificador que ha sido creado, con los parámetros que se han asignado de acuerdo a la configuración por defecto de Scikit-Learn: número de vecinos (`n_neighbors`), distancia (`metric`), pesos (`weights`), etc. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4xR7OPdHFjy"
      },
      "source": [
        "### **3.5 Cálculo de la calidad del modelo generado**\n",
        "\n",
        "Una de las etapas durante el uso de Machine Learning es contrastar si se han alcanzado los resultados de calidad deseados, para lo que se utilizará la partición de test. En Scikit-Learn, para todos los estimadores de tipo supervisados, se cuenta con los siguientes métodos por defecto para realizar la predicción u obtener las métricas de calidad directamente:\n",
        "\n",
        "-\t`model.predict()`: dado un modelo que ya está entrenado, predice la clase sobre un nuevo conjunto de datos. Este método acepta un único parámetro: los nuevos datos de test `X_test` (p.ej. `model.predict(X_test)`) y devuelve la clase predicha para instancia del conjunto de datos.\n",
        "- `model.predict_proba()`: para problemas de clasificación, algunos algoritmos también tienen este método. Devuelve la probabilidad de que cada instancia pertenezca a cada una de las clases. La clase con máxima probabilidad coincidiría con la etiqueta predicha por `model.predict()`. Se utilizará fundamentalmente para generar la curva ROC y la medida AUC.\n",
        "-\t`model.score()`: casi todos los clasificadoreas implementan un método denominado \"puntuación\". Para clasificadores, el método ```score()``` está asociado al porcentaje de ejemplos bien clasificados (accuracy). \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIyn_gJabUHm"
      },
      "source": [
        "El siguiente bloque de código utiliza el algoritmo *kNN* aprendido en el bloque anterior para generar predicciones sobre el conjunto de test (variable ```X_test```). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyT0jqnxawQR"
      },
      "source": [
        "y_pred = knn.predict(X_test) # predicción de cada etiqueta \n",
        "\n",
        "# imprimimos la etiqueta calculada para los 10 primeros datos de X_test\n",
        "print(y_pred[:10]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-ycI7j3ayvq"
      },
      "source": [
        "Ahora, la puntuación mediante accuracy puede calcularse utilizando la función correspondiente de la biblioteca de *Scikit-Learn*, tal como se indicó en la Sección 2 del presente NoteBook. Para ello, basta comparar la salida real `y_test` con la predicción realizada por *kNN* `y_pred`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF11UC_2HFjz"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "acc_score = accuracy_score(y_test, y_pred)\n",
        "print(acc_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgrB9dhVHFj1"
      },
      "source": [
        "El acierto no es muy alto. Podemos ver cuántas muestras han sido mal clasificadas creando una matriz de confusión, del mismo modo que se estudió en la pasada Sección 2.\n",
        "\n",
        "En esta matriz, las filas representan la clase real, y las columnas representan la clase predicha. Cuantas más instancias estén en la diagonal, mejor puntuación será alcanazada. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfNvxIA4HFj2"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "m = confusion_matrix(y_test, y_pred)\n",
        "print(m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtQrlaKyb5gv"
      },
      "source": [
        "### **3.6 Validación cruzada hecha simple**\n",
        "\n",
        "Es imprescindible realizar una validación del modelo obtenido en la fase de aprendizaje. Entre las alternativas para este proceso, la más apropiada es la validación cruzada de $k$ particiones. Como dicho procedimiento es muy común en Machine Learning, hay funciones para hacerlo de forma flexible y con poco código. \n",
        "\n",
        "El paquete `sklearn.model_selection` contiene todas las funciones relacionadas con validación de modelos. Aunque en el pasado **Módulo 3** se explicó cómo generar las particiones \"a mano\", la forma más sencilla es utilizar la función `cross_val_score` que recibe un estimador (clasificador) y un conjunto de datos y hace todo el proceso de forma automática. En otras palabras, devuelve un `array` (un tipo de dato similar a una lista) con las predicciones obtenidas para cada partición."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtolUXSYcPId"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(knn, X, y) #por defecto 5 particiones\n",
        "\n",
        "print(scores) #los valores individuales de cada partición\n",
        "print(np.mean(scores)) #la media de acierto global\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9N6RiZkdJdx"
      },
      "source": [
        "Por defecto, ```cross_val_score``` utiliza ```StratifiedKFold``` para clasificación. Tal como se explicó en el **Modulo 3**, el tipo de particionamiento estratificado asegura que la proporción de ejemplos por clase se respeta en cada partición. \n",
        "\n",
        "A modo de recordatorio, en el caso de un conjunto de datos binario para clasificación que esté no balanceado, es decir, si se tiene un 90% de instancias de la clase \"neg\", significaría que en cada partición debería haber un 90% de instancias en la clase \"neg\". \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyRqW3YcdjwU"
      },
      "source": [
        "### **3.7 Visualización de la calidad del modelo**\n",
        "\n",
        "En primer lugar, resulta muy importante chequear la salida del modelo en cada una de las clases mediante la matriz de confusión. Anteriormente ya se mostró este información, pudiendo así contrastar si existe algún tipo de sesgo hacia una de las clases. En este caso,  es preferible generar gráficos que sean más cómodos de visualizar en un informe.  \n",
        "\n",
        "Para esta tarea, se utilizará el método ```plot_confusion_matrix()``` de acuerdo al siguiente ejemplo:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l27JQC5KI877"
      },
      "source": [
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#el parámetro cmap utilizar un mapa de color en azules para ser cómodo a la vista\n",
        "metrics.plot_confusion_matrix(knn, X_test, y_test,cmap=plt.cm.Blues)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SkzQOTkLMRb"
      },
      "source": [
        "También se pueden calcular el valor AUC mediante el uso de `roc_auc_score`. Para ello, es imprescindible utilizar el método `predict_proba()` del clasificador, ya que se necesitan los valores de probabilidad, y no las clases de salida. \n",
        "\n",
        "Por último, se puede pinta la curvas ROC con la función `plot_roc_curve`. En este caso el método recibe tres parámetros: el clasificador, el conjunto de instancias, y la lista de valores de salida. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xlO3a_qeXoQ"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "y_prob = knn.predict_proba(X_test)\n",
        "\n",
        "auc_knn = metrics.roc_auc_score(y_test, y_prob[:,1]) \n",
        "print(\"El valor de AUC para kNN es\", auc_knn)\n",
        "\n",
        "metrics.plot_roc_curve(knn, X_test, y_test) #pintamos la curva"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teqEfQI-JM6A"
      },
      "source": [
        "## **REFERENCIAS BIBLIOGRÁFICAS**\n",
        "\n",
        "-\tHan, J., Kamber, M., Pei, J. (2011). Data Mining: Concepts and Techniques. San Francisco, CA, USA: Morgan Kaufmann Publishers. ISBN: 0123814790, 9780123814791\n",
        "-\tWitten, I. H., Frank, E., Hall, M. A., Pal, C. J. (2017). Data mining: practical machine learning tools and techniques. Amsterdam; London: Morgan Kaufmann. ISBN: 9780128042915 0128042915\n",
        "- Scikit-Learn: Metrics and scoring: quantifying the quality of predictions https://scikit-learn.org/stable/modules/model_evaluation.html (visitado el 25 de Junio de 2020).\n",
        "\n",
        "### **Referencias adicionales**\n",
        "\n",
        "-\tAlpaydin, E. (2016). Machine Learning: The New AI. MIT Press. ISBN: 9780262529518\n",
        "- Towards Data Science: Various ways to evaluate a machine learning model’s performance https://towardsdatascience.com/various-ways-to-evaluate-a-machine-learning-models-performance-230449055f15 (visitado el 25 de Junio de 2020). \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5_VU5syYO-s"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "MOOC Machine Learning y Big Data para la Bioinformática (1ª edición)   \n",
        "http://abierta.ugr.es     \n",
        "    \n",
        "![CC](https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-nd.png)\n",
        "</div>    "
      ]
    }
  ]
}